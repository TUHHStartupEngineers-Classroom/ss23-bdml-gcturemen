{
  "hash": "18be4b3c1fffb120fb3ca192b9ea056a",
  "result": {
    "markdown": "---\ntitle: \"Performance Measures\"\nauthor: \"Gani Cem Türemen\"\n---\n\n\n# Challenge Summary\n\nFor the challenge, we will continue working on the Product Backorders dataset. The goal here is to visualize various performance metrics of H2O models to simplify evaluation of them.\n\n# Objectives\n\nWe will apply our learning of H2O Automated Machine Learning to predict backorder status and visualize performance metrics to evaluate models.\n\n# Solution\n\n## Import Libraries\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-1_5682568294d4157a7ca86d9b555be41e'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rsample)\nlibrary(h2o)\nlibrary(recipes)\nlibrary(cowplot)\nlibrary(glue)\n```\n:::\n\n\n## Load the training & test dataset\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-2_2376f3778db2b1507b2827f5c7ac3c41'}\n\n```{.r .cell-code}\nproduct_backorders_tbl <- read_csv(\"data/product_backorders.csv\")\n\nproduct_backorders_tbl %>% glimpse()\n```\n:::\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-3_0af88d2943c357012eceeb4fe219fadd'}\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 19,053\n#> Columns: 23\n#> $ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n#> $ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n#> $ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n#> $ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n#> $ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n#> $ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n#> $ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n#> $ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n#> $ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n#> $ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n#> $ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n#> $ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n#> $ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#> $ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n#> $ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n#> $ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n#> $ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#> $ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#> $ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n#> $ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n#> $ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#> $ went_on_backorder <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n```\n:::\n:::\n\n\nSplit the data into training and test sets:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-4_1d285e883fa3acb237edefbd406a2538'}\n\n```{.r .cell-code}\nset.seed(seed = 777)\nsplit_obj <- initial_split(product_backorders_tbl, prop = 0.80)\n\ntrain_set_tbl <- training(split_obj)\ntest_set_tbl  <- testing(split_obj)\n```\n:::\n\n\nSince some columns such as `deck_risk` are not numeric, they have to be converted into factor. The recipe below will take care of that:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-5_d2e7380d8ba3b0d54f27e94174f418c2'}\n\n```{.r .cell-code}\nrecipe_obj <- recipe(went_on_backorder ~., data = train_set_tbl) %>% \n  step_zv(all_predictors()) %>% \n  step_mutate_at(potential_issue,\n                 deck_risk,\n                 oe_constraint,\n                 ppap_risk,\n                 stop_auto_buy,\n                 rev_stop,\n                 went_on_backorder,\n                 fn = as.factor) %>% \n  prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_set_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_set_tbl)\n\ntrain_tbl %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 15,242\n#> Columns: 23\n#> $ sku               <dbl> 1370478, 1423347, 1704266, 2258894, 3000725, 2888766…\n#> $ national_inv      <dbl> 4, 59, 1, 9, 151, 6, 195, 66, 52, 0, 25, 1, 4, 2, 10…\n#> $ lead_time         <dbl> 12, NA, 8, 2, 8, 2, 8, 8, 14, 2, 4, 4, 8, 8, 2, 8, 5…\n#> $ in_transit_qty    <dbl> 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ forecast_3_month  <dbl> 0, 0, 0, 0, 0, 0, 0, 122, 20, 0, 9, 15, 0, 28, 0, 0,…\n#> $ forecast_6_month  <dbl> 0, 0, 0, 0, 0, 0, 0, 214, 35, 0, 18, 15, 0, 61, 0, 0…\n#> $ forecast_9_month  <dbl> 1, 0, 0, 0, 0, 0, 0, 306, 65, 0, 18, 21, 0, 94, 0, 0…\n#> $ sales_1_month     <dbl> 1, 0, 1, 0, 0, 0, 2, 36, 13, 0, 9, 4, 0, 3, 0, 0, 0,…\n#> $ sales_3_month     <dbl> 1, 7, 1, 0, 15, 0, 4, 119, 31, 0, 24, 9, 0, 26, 0, 0…\n#> $ sales_6_month     <dbl> 3, 20, 1, 0, 27, 0, 12, 209, 78, 0, 43, 15, 0, 56, 0…\n#> $ sales_9_month     <dbl> 3, 28, 1, 3, 43, 0, 16, 322, 121, 0, 75, 22, 1, 82, …\n#> $ min_bank          <dbl> 0, 0, 0, 0, 7, 0, 1, 45, 21, 1, 0, 2, 1, 6, 0, 0, 1,…\n#> $ potential_issue   <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n#> $ pieces_past_due   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ perf_6_month_avg  <dbl> 0.87, -99.00, 0.99, 0.99, 0.98, 0.98, 0.88, 0.98, 0.…\n#> $ perf_12_month_avg <dbl> 0.67, -99.00, 0.98, 0.99, 0.96, 0.99, 0.91, 0.99, 0.…\n#> $ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ deck_risk         <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, No, No…\n#> $ oe_constraint     <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n#> $ ppap_risk         <fct> No, Yes, No, No, No, No, No, No, Yes, No, No, No, No…\n#> $ stop_auto_buy     <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n#> $ rev_stop          <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n#> $ went_on_backorder <fct> No, No, Yes, No, No, No, No, No, No, No, No, Yes, No…\n```\n:::\n:::\n\n\n## Specify the response and predictor variables\n\nTo determine the backorder status `went_on_backorder`, all the other columns will be used as predictors:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-6_25f4305a10e8c4bda422cb4cc92aa497'}\n\n```{.r .cell-code}\nh2o.init()\n\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.80), seed = 767)\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), y)\n```\n:::\n\n    \n## Run AutoML\n\nSet 600 seconds for `max_runtime_secs` and 15 for `max_models` to limit the computation time:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-7_d2127da65286f8a76960e90d41e67875'}\n\n```{.r .cell-code}\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 600,\n  max_models = 15,\n  nfolds            = 5,\n  include_algos = c(\"DeepLearning\", \"GBM\", \"XGBoost\", \"GLM\", \"DRF\")\n)\n```\n:::\n\n\n## View the leaderboard\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-8_c1556bfaf53b0454fe10563a63287890'}\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                                     model_id       auc   logloss     aucpr\n#> 1              GBM_3_AutoML_1_20230612_84439 0.9460585 0.1782440 0.7492513\n#> 2              GBM_1_AutoML_1_20230612_84439 0.9454817 0.1792050 0.7391388\n#> 3 GBM_grid_1_AutoML_1_20230612_84439_model_3 0.9453233 0.1782869 0.7453088\n#> 4              GBM_2_AutoML_1_20230612_84439 0.9448476 0.1790129 0.7546212\n#> 5              DRF_1_AutoML_1_20230612_84439 0.9433694 0.2031015 0.7311273\n#> 6              GBM_4_AutoML_1_20230612_84439 0.9427084 0.1797984 0.7508803\n#>   mean_per_class_error      rmse        mse\n#> 1            0.1452358 0.2284730 0.05219991\n#> 2            0.1746839 0.2304370 0.05310123\n#> 3            0.1600785 0.2282351 0.05209127\n#> 4            0.1586459 0.2289302 0.05240905\n#> 5            0.1692491 0.2448786 0.05996551\n#> 6            0.1716661 0.2288689 0.05238100\n#> \n#> [12 rows x 7 columns]\n```\n:::\n:::\n\n\n## Leaderboard visualization\n\nFirst, leaderboard will be converted into long format to be able to visualize it easier:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-9_03a8c425be17279887251882ec976a20'}\n\n```{.r .cell-code}\nmodel_leaderboard <- automl_models_h2o@leaderboard %>%\n  as_tibble() %>%\n  select(-c(aucpr, mean_per_class_error, rmse, mse)) %>%\n  mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n  rownames_to_column(var = \"row_name\") %>%\n  mutate(model_id   = as_factor(model_id) %>% reorder(auc), \n         model_type = as.factor(model_type)) %>% \n  pivot_longer(cols = -c(model_id, model_type, row_name), \n               names_to = \"key\", \n               values_to = \"value\", \n               names_transform = list(key = forcats::fct_inorder)) %>% \n  mutate(model_id = paste0(row_name, \". \", model_id) %>% as_factor() %>% fct_rev())\n\nmodel_leaderboard %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 24\n#> Columns: 5\n#> $ row_name   <chr> \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", \"6\",…\n#> $ model_id   <fct> 1. GBM_3_AutoML_1_20230612_84439, 1. GBM_3_AutoML_1_2023061…\n#> $ model_type <fct> GBM, GBM, GBM, GBM, GBM, GBM, GBM, GBM, DRF, DRF, GBM, GBM,…\n#> $ key        <fct> auc, logloss, auc, logloss, auc, logloss, auc, logloss, auc…\n#> $ value      <dbl> 0.9460585, 0.1782440, 0.9454817, 0.1792050, 0.9453233, 0.17…\n```\n:::\n:::\n\n\nVisualize the long format leaderboard:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-10_8a6880a5005ac4310347a59a766b90fa'}\n\n```{.r .cell-code}\nmodel_leaderboard %>%\n  ggplot(aes(value, model_id, color = model_type)) +\n  geom_point(size = 3) +\n  geom_label(aes(label = round(value, 3), hjust = \"inward\"), label.padding = unit(0.10, \"lines\"), size = 3) +\n  facet_wrap(~ key, scales = \"free_x\") +\n  labs(title = \"Leaderboard Metrics\",\n       subtitle = paste0(\"Ordered by: \", \"auc\"),\n       y = \"Model Position, Model ID\",\n       x = \"\",\n       col = \"Model Type\") + \n  theme(\n    legend.position = \"bottom\",\n    legend.background = element_rect(fill = NA, color = \"white\"),\n    panel.background = element_blank(),\n    panel.border = element_rect(color = \"white\", fill = NA),\n    plot.background = element_rect(fill = \"#222222\", color = \"#222222\"),\n    line = element_line(color = \"white\"),\n    text = element_text(color = \"white\", size = 7),\n    axis.ticks = element_line(color = \"white\"),\n    axis.text = element_text(color = \"white\", size = 6),\n  )\n```\n\n::: {.cell-output-display}\n![](05_performance_measures_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nFrom the figure, it is seen that `AUC` and `LogLoss` metrics behave mostly as expected. Generally with increasing model performance, an increase in `AUC` and a decrease in `LogLoss` is observed.\n\n## Tune a model with grid search\n\n\n\n\n\nA `Deep Learning` model will be tuned in this section. First, the Deep Learning model from the leaderboard is extracted to be used for comparison purposes:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-12_52a6b991d1261013f1aedb68cdd39941'}\n\n```{.r .cell-code}\ndl_model_automl <- automl_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(11) %>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> DeepLearning_1_AutoML_1_20230612_84439\n```\n:::\n:::\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-13_dc574b2181075c1004af188e2a5563cd'}\n\n```{.r .cell-code}\np_dl_model_automl <- h2o.performance(dl_model_automl, newdata = as.h2o(test_tbl))\n\np_dl_model_automl\n```\n:::\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-14_7ca466137a7379a9856922edc8dd0815'}\n::: {.cell-output .cell-output-stdout}\n```\n#> H2OBinomialMetrics: deeplearning\n#> \n#> MSE:  0.09505643\n#> RMSE:  0.3083122\n#> LogLoss:  0.321205\n#> Mean Per-Class Error:  0.3228888\n#> AUC:  0.7750419\n#> AUCPR:  0.350434\n#> Gini:  0.5500839\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     2905 441 0.131799  =441/3346\n#> Yes     239 226 0.513978   =239/465\n#> Totals 3144 667 0.178431  =680/3811\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.238236    0.399293 141\n#> 2                       max f2  0.179913    0.526316 212\n#> 3                 max f0point5  0.306734    0.385791  85\n#> 4                 max accuracy  0.386126    0.884807  52\n#> 5                max precision  0.946199    1.000000   0\n#> 6                   max recall  0.000058    1.000000 399\n#> 7              max specificity  0.946199    1.000000   0\n#> 8             max absolute_mcc  0.238236    0.305113 141\n#> 9   max min_per_class_accuracy  0.194376    0.699342 195\n#> 10 max mean_per_class_accuracy  0.179913    0.708168 212\n#> 11                     max tns  0.946199 3346.000000   0\n#> 12                     max fns  0.946199  464.000000   0\n#> 13                     max fps  0.000058 3346.000000 399\n#> 14                     max tps  0.000058  465.000000 399\n#> 15                     max tnr  0.946199    1.000000   0\n#> 16                     max fnr  0.946199    0.997849   0\n#> 17                     max fpr  0.000058    1.000000 399\n#> 18                     max tpr  0.000058    1.000000 399\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n```\n:::\n:::\n\n\n\n\nIt is seen that this model has an `AUC` value of 0.775 and a `LogLoss` value of 0.321. Using grid search, there is a possibility to find a model with better performance metrics.\n\nUse the hyperparameters `hidden` and `epochs` for tuning:\n\n    hidden: Hidden layer size. \n    lambda: The number of times to iterate the data set.\n    \n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-16_2ba21bad15bc24749ce91bb48eb9ef70'}\n\n```{.r .cell-code}\nmodel_grid <- h2o.grid(\n  algorithm = \"deeplearning\",\n  grid_id = \"deeplearning_grid_01\",\n  x = x,\n  y = y,\n  training_frame = train_h2o,\n  validation_frame = valid_h2o,\n  max_runtime_secs  = 600,\n  nfolds = 5,\n  hyper_params = list(\n    #activation = c(\"tanh\", \"rectifier\"),\n    hidden = list(c(10, 10), c(15, 15), c(10, 10, 10), c(15, 15, 15)),\n    epochs = c(50, 100, 200)\n  )\n)\n```\n:::\n\n\nGet the grid search result and order models by decreasing AUC: \n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-17_43f11427d2f0e9044ed804e616801ffa'}\n\n```{.r .cell-code}\nh2o.getGrid(grid_id = \"deeplearning_grid_01\", sort_by = \"auc\", decreasing = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> H2O Grid Details\n#> ================\n#> \n#> Grid ID: deeplearning_grid_01 \n#> Used hyper parameters: \n#>   -  epochs \n#>   -  hidden \n#> Number of models: 12 \n#> Number of failed models: 0 \n#> \n#> Hyper-Parameter Search Summary: ordered by decreasing auc\n#>       epochs       hidden                     model_ids     auc\n#> 1  204.75291 [10, 10, 10]  deeplearning_grid_01_model_9 0.89661\n#> 2  203.22186     [15, 15]  deeplearning_grid_01_model_6 0.88974\n#> 3  204.79010 [15, 15, 15] deeplearning_grid_01_model_12 0.88580\n#> 4  103.99907 [10, 10, 10]  deeplearning_grid_01_model_8 0.88199\n#> 5  203.19357     [10, 10]  deeplearning_grid_01_model_3 0.87900\n#> 6  104.00621 [15, 15, 15] deeplearning_grid_01_model_11 0.86775\n#> 7  103.98990     [10, 10]  deeplearning_grid_01_model_2 0.86551\n#> 8  103.99660     [15, 15]  deeplearning_grid_01_model_5 0.86497\n#> 9   52.01461     [10, 10]  deeplearning_grid_01_model_1 0.84500\n#> 10  52.00563 [15, 15, 15] deeplearning_grid_01_model_10 0.84160\n#> 11  51.99446 [10, 10, 10]  deeplearning_grid_01_model_7 0.83979\n#> 12  51.98538     [15, 15]  deeplearning_grid_01_model_4 0.83636\n```\n:::\n:::\n\n\nExtract the leader model of the grid search: \n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-18_3f843af6f0c55eca6bd07c0f8763da5f'}\n\n```{.r .cell-code}\ndl_model_grid_search <- h2o.getModel(\"deeplearning_grid_01_model_9\")\n```\n:::\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-19_3c7501b496be1f7088bdd1ebb9d82e03'}\n\n```{.r .cell-code}\ndl_model_grid_search %>% h2o.auc(train = T, valid = T, xval = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     train     valid      xval \n#> 0.9064394 0.9012377 0.8966053\n```\n:::\n:::\n\n\nNo overfitting is observed since the AUC value for training, validation and cross-validation are all similar.\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-20_9c6290b1cee018d8c4e0c37d5050dd3c'}\n\n```{.r .cell-code}\np_dl_model_grid_search <- dl_model_grid_search %>% h2o.performance(newdata = as.h2o(test_tbl))\n\np_dl_model_grid_search\n```\n:::\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-21_4845c6b77d587379efe836ceb1832143'}\n::: {.cell-output .cell-output-stdout}\n```\n#> H2OBinomialMetrics: deeplearning\n#> \n#> MSE:  0.07524832\n#> RMSE:  0.2743143\n#> LogLoss:  0.2631152\n#> Mean Per-Class Error:  0.2072473\n#> AUC:  0.8954788\n#> AUCPR:  0.6113704\n#> Gini:  0.7909576\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     3132 214 0.063957  =214/3346\n#> Yes     163 302 0.350538   =163/465\n#> Totals 3295 516 0.098924  =377/3811\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.449638    0.615698 141\n#> 2                       max f2  0.342839    0.681644 188\n#> 3                 max f0point5  0.629235    0.631579  72\n#> 4                 max accuracy  0.629235    0.909473  72\n#> 5                max precision  0.998544    1.000000   0\n#> 6                   max recall  0.000051    1.000000 399\n#> 7              max specificity  0.998544    1.000000   0\n#> 8             max absolute_mcc  0.449638    0.560103 141\n#> 9   max min_per_class_accuracy  0.273284    0.821505 223\n#> 10 max mean_per_class_accuracy  0.265519    0.824108 227\n#> 11                     max tns  0.998544 3346.000000   0\n#> 12                     max fns  0.998544  462.000000   0\n#> 13                     max fps  0.000051 3346.000000 399\n#> 14                     max tps  0.000051  465.000000 399\n#> 15                     max tnr  0.998544    1.000000   0\n#> 16                     max fnr  0.998544    0.993548   0\n#> 17                     max fpr  0.000051    1.000000 399\n#> 18                     max tpr  0.000051    1.000000 399\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n```\n:::\n:::\n\n\nIt is seen that by using grid search it was possible find a model with improved performance metrics compared to the base model found in the previous section.\n\n|             Model               |  AUC  |  LogLoss  |\n|:-------------------------------:|:-----:|:---------:|\n| dl_model_automl                 | 0.775 |   0.321   |\n| dl_model_grid_search            | 0.895 |   0.263   |\n\n## Visualize the trade-off between the precision and the recall and the optimal threshold\n\nConvert the performance object of the model into a series of different metrics which vary by threshold and store it as `p_dl_model_grid_search_tbl`:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-22_c4ec212509d90c7b1b7cbadc9e273c0c'}\n\n```{.r .cell-code}\np_dl_model_grid_search_tbl <- p_dl_model_grid_search %>% \n  h2o.metric() %>%\n  as_tibble() %>%\n  mutate(auc = h2o.auc(p_dl_model_grid_search))\n```\n:::\n\n\nVisualize `precision` and `recall` by selecting corresponding columns:\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-23_f544b2a36f18affc95a7c7f10d6ce9a6'}\n\n```{.r .cell-code}\np_dl_model_grid_search_tbl %>% select(c(threshold, precision, recall)) %>% \n  pivot_longer(cols = c(precision, recall), names_to = \"key\", values_to = \"values\") %>%\n  \n  ggplot(aes(x = threshold, y = values, color = key)) +\n  geom_line(size = 1) +\n  scale_color_manual(values = c(\"#2DC6D6\", \"#FF8014\")) +\n  geom_vline(xintercept = h2o.find_threshold_by_max_metric(p_dl_model_grid_search, \"f1\"), \n             color = 'red', size = 1) +\n  labs(title = \"Precision vs Recall\", subtitle = \"dl_model_grid_search\", y = \"Value\", x = \"Threshold\", col = \"\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.background = element_rect(fill = NA, color = \"white\"),\n    legend.key = element_blank(),\n    panel.background = element_blank(),\n    panel.border = element_rect(color = \"white\", fill = NA),\n    plot.background = element_rect(fill = \"#222222\", color = \"#222222\"),\n    line = element_line(color = \"white\"),\n    text = element_text(color = \"white\"),\n    axis.ticks = element_line(color = \"white\"),\n    axis.text = element_text(color = \"white\")\n  )\n```\n:::\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-24_16172e4aa3db8148350bf26cf5198347'}\n::: {.cell-output-display}\n![](05_performance_measures_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nFrom the figure, values of `precision` and `recall` can be seen as the threshold value increases. The vertical red line indicates the optimal threshold value which maximizes the `F1`.\n\n## ROC Plot\n\n\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-26_0028bb38ca56b193d2b51017773634cd'}\n\n```{.r .cell-code}\nroc_plot <- ggplot() + \n  geom_line(data = p_dl_model_automl_tbl, \n            aes(x = fpr, y = tpr, color = \"dl_model_automl\"), \n            size = 1) +\n  geom_line(data = p_dl_model_grid_search_tbl, \n            aes(x = fpr, y = tpr, color = \"dl_model_grid_search\"), \n            size = 1) +\n  geom_abline(color = \"red\", \n              linetype = \"dotted\", \n              size = 1) +\n  scale_color_manual(name = \"\", \n                     values = c(\"dl_model_automl\" = \"#2DC6D6\", \"dl_model_grid_search\" = \"#FF8014\")) +\n  labs(title = \"ROC Plot\", \n       subtitle = \"Performance Comparison of dl_model_automl and dl_model_grid_search\", \n       x = \"False Positive Rate (FPR)\", \n       y = \"True Positive Rate (TPR)\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.background = element_rect(fill = NA, color = \"white\"),\n    legend.key = element_blank(),\n    panel.background = element_blank(),\n    panel.border = element_rect(color = \"white\", fill = NA),\n    plot.background = element_rect(fill = \"#222222\", color = \"#222222\"),\n    line = element_line(color = \"white\"),\n    text = element_text(color = \"white\"),\n    axis.ticks = element_line(color = \"white\"),\n    axis.text = element_text(color = \"white\")\n  )\n\nroc_plot\n```\n\n::: {.cell-output-display}\n![](05_performance_measures_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nIt is also seen from the ROC plot that the model found with grid search (`dl_model_grid_search`) has better performance since it has a larger area under its curve compared to the model that has been found automatically (`dl_model_automl`). \n\n## Precision vs Recall Plot\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-27_5dad7cbfbe20079bfc2b31e52e94d6f0'}\n\n```{.r .cell-code}\npr_plot <- ggplot() +\n  geom_line(data = p_dl_model_automl_tbl, \n            aes(x = recall, y = precision, color = \"dl_model_automl\"), \n            size = 1) +\n  geom_line(data = p_dl_model_grid_search_tbl, \n            aes(x = recall, y = precision, color = \"dl_model_grid_search\"), \n            size = 1) +\n  scale_color_manual(name = \"\", \n                     values = c(\"dl_model_automl\" = \"#2DC6D6\", \"dl_model_grid_search\" = \"#FF8014\")) +\n  labs(title = \"Precision vs Recall Plot\", \n       subtitle = \"Performance Comparison of dl_model_automl and dl_model_grid_search\", \n       x = \"Recall\", \n       y = \"Precision\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.background = element_rect(fill = NA, color = \"white\"),\n    legend.key = element_blank(),\n    panel.background = element_blank(),\n    panel.border = element_rect(color = \"white\", fill = NA),\n    plot.background = element_rect(fill = \"#222222\", color = \"#222222\"),\n    line = element_line(color = \"white\"),\n    text = element_text(color = \"white\"),\n    axis.ticks = element_line(color = \"white\"),\n    axis.text = element_text(color = \"white\")\n  )\n\npr_plot\n```\n\n::: {.cell-output-display}\n![](05_performance_measures_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nA similar observation can also be made for the precision-recall curve. It is seen that `dl_model_grid_search` performs better compared to `dl_model_automl` since its curve is closer to the upper right corner of the plot (which means the model can maintain higher precision while recall increases).\n\n## Gain Plot\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-28_891511fe3c2ff04ca84f5e156242b5eb'}\n\n```{.r .cell-code}\ngain_lift_automl_tbl <- p_dl_model_automl %>%\n  h2o.gainsLift() %>%\n  as_tibble()\n\ngain_automl_transformed_tbl <- gain_lift_automl_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"lift\")) %>%\n  mutate(baseline = cumulative_data_fraction) %>%\n  rename(gain     = cumulative_capture_rate) %>%\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_lift_grid_tbl <- p_dl_model_grid_search %>%\n  h2o.gainsLift() %>%\n  as_tibble()\n\ngain_grid_transformed_tbl <- gain_lift_grid_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"lift\")) %>%\n  mutate(baseline = cumulative_data_fraction) %>%\n  rename(gain     = cumulative_capture_rate) %>%\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n```\n:::\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-29_075ed578c1ec47400c7094a6de913ab3'}\n\n```{.r .cell-code}\ngain_plot <- ggplot() +\n  geom_line(data = gain_automl_transformed_tbl %>% filter(str_detect(key, \"gain\")), \n            aes(x = cumulative_data_fraction, y = value, color = \"dl_model_automl\"),\n            size = 1) +\n  geom_line(data = gain_grid_transformed_tbl %>% filter(str_detect(key, \"gain\")), \n            aes(x = cumulative_data_fraction, y = value, color = \"dl_model_grid_search\"),\n            size = 1) +\n  geom_abline(color = \"red\", \n            linetype = \"dotted\", \n            size = 1) +\n  scale_color_manual(name = \"\", \n                     values = c(\"dl_model_automl\" = \"#2DC6D6\", \n                                \"dl_model_grid_search\" = \"#FF8014\")) +\n  labs(title = \"Gain Chart\", x = \"Cumulative Data Fraction\", y = \"Gain\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.background = element_rect(fill = NA, color = \"white\"),\n    legend.key = element_blank(),\n    panel.background = element_blank(),\n    panel.border = element_rect(color = \"white\", fill = NA),\n    plot.background = element_rect(fill = \"#222222\", color = \"#222222\"),\n    line = element_line(color = \"white\"),\n    text = element_text(color = \"white\"),\n    axis.ticks = element_line(color = \"white\"),\n    axis.text = element_text(color = \"white\")\n  )\n\ngain_plot\n```\n\n::: {.cell-output-display}\n![](05_performance_measures_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nFrom the figure, it can be seen that with `dl_model_grid_search`, the ability to target backorders from a given size of data has increased significantly, especially at the lower end of the x-axis (where it is important).\n\n## Lift Plot\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-30_645ceeafd3698f7bde88d71744d5d4fc'}\n\n```{.r .cell-code}\nlift_automl_transformed_tbl <- gain_lift_automl_tbl %>%\n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"capture\")) %>%\n  mutate(baseline = 1) %>%\n  rename(lift = cumulative_lift) %>%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n\nlift_grid_transformed_tbl <- gain_lift_grid_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"capture\")) %>%\n  mutate(baseline = 1) %>%\n  rename(lift = cumulative_lift) %>%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n```\n:::\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-31_ee2f197b465a764ef3bdaf097b22eaa1'}\n\n```{.r .cell-code}\nlift_plot <- ggplot() +\n  geom_line(data = lift_automl_transformed_tbl %>% filter(str_detect(key, \"lift\")), \n            aes(x = cumulative_data_fraction, y = value, color = \"dl_model_automl\"),\n            size = 1) +\n  geom_line(data = lift_grid_transformed_tbl %>% filter(str_detect(key, \"lift\")), \n            aes(x = cumulative_data_fraction, y = value, color = \"dl_model_grid_search\"),\n            size = 1) +\n  geom_hline(yintercept = 1,\n             color = \"red\", \n            linetype = \"dotted\", \n            size = 1) +\n  scale_color_manual(name = \"\", \n                     values = c(\"dl_model_automl\" = \"#2DC6D6\", \n                                \"dl_model_grid_search\" = \"#FF8014\")) +\n  labs(title = \"Lift Chart\", x = \"Cumulative Data Fraction\", y = \"Lift\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.background = element_rect(fill = NA, color = \"white\"),\n    legend.key = element_blank(),\n    panel.background = element_blank(),\n    panel.border = element_rect(color = \"white\", fill = NA),\n    plot.background = element_rect(fill = \"#222222\", color = \"#222222\"),\n    line = element_line(color = \"white\"),\n    text = element_text(color = \"white\"),\n    axis.ticks = element_line(color = \"white\"),\n    axis.text = element_text(color = \"white\")\n  )\n\nlift_plot\n```\n\n::: {.cell-output-display}\n![](05_performance_measures_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nSimilarly, it is seen from the figure that `dl_model_grid_search` is better at targeting backorders for the same size of data when compared with `dl_model_automl`.\n\n## Dashboard with cowplot\n\n\n::: {.cell hash='05_performance_measures_cache/html/unnamed-chunk-32_c73ea75193d4fb40bed0180faf70aea9'}\n\n```{.r .cell-code}\np_legend <- get_legend(roc_plot)\n\nroc_plot <- roc_plot + theme(legend.position = \"none\") + labs(subtitle = element_blank())\npr_plot <- pr_plot + theme(legend.position = \"none\") + labs(subtitle = element_blank())\ngain_plot <- gain_plot + theme(legend.position = \"none\")\nlift_plot <- lift_plot + theme(legend.position = \"none\")\n\np <- plot_grid(roc_plot, pr_plot, gain_plot, lift_plot, ncol = 2)\n\np_title <- ggdraw() + \n  draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", color = \"white\")\n  \np_subtitle <- ggdraw() + draw_label(glue(\"\"), size = 10, color = \"white\")\n  \ncombined_plot <- plot_grid(p_title, \n                           p_subtitle, \n                           p, \n                           p_legend, \n                           ncol = 1, \n                           rel_heights = c(0.05, 0.05, 1, 0.05 * 4)) +\n  theme(\n    legend.position = \"bottom\",\n    legend.background = element_rect(fill = NA, color = \"white\"),\n    panel.background = element_blank(),\n    panel.border = element_rect(color = \"#222222\", fill = NA),\n    plot.background = element_rect(fill = \"#222222\", color = \"#222222\"),\n    line = element_line(color = \"white\"),\n    text = element_text(color = \"white\"),\n    axis.ticks = element_line(color = \"white\"),\n    axis.text = element_text(color = \"white\")\n  )\n\ncombined_plot\n```\n\n::: {.cell-output-display}\n![](05_performance_measures_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}